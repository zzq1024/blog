# 第一节：MySQL奥义

### 基础

#### char与varchar

* char和varchar 后面的长度表示的是字符的个数，而不是字节数。

* 如果某个数据表里的数据行的长度是可变的，那么，为了节约存储空间，MySQL会把这个数据表里的固定长度类型的数据列转换为相应的可变长度类型．例外：长度小于4个字符的char数据列不会被转换为varchar类型。

* 区别：
  * char 表示定长，长度固定，varchar表示变长，即长度可变
  * char最多能存放的**字符**个数 255，和编码无关；varchar最大有效长度是 65532 字节，在varchar存字符串的时候，第一个字节是空的，不存任何的数据，然后还需要两个字节来存放字符串的长度。所以有效长度就是 65535 - 1 - 2 = 65532字节，字符根据编码来定。
  * char的效率高，没有碎片，尤其更新比较频繁的时候，方便数据文件指针的操作，varchar更新数据需要重新计算长度
  * varchar相对来说比较灵活，可动态分配空间，char设置长度不合理时可能会浪费空间
* 如果已经对含有可变长度的表（varchar、blob、text）进行了很多更改，可以使用OPTIMIZE TABLE重新利用未使用的空间，并整理数据文件的碎片。

#### redo log与binlog

* redo log是innodb引擎提供的，binlog是mysql server自带的；
* redo log 记录 做了什么改动（比如把某个字段从0改成了1），binlog 记录 是怎么修改的（记录sql语句或者 记录更新前后的行）
* redo log 记录的，即使异常重启，都会刷新到磁盘（满血复活），而 bin log 记录的， 则主要用于备份



### 事务

#### 特性

* **原子性**：事务中包含的程序作为数据库的逻辑工作单位，它对数据库中的数据进行操作时，要么全部执行，要么都不执行
* **一致性**：一个事务执行前和执行后，数据库都必须要处于一致性的状态。（你给小A的卡里转了500块，不管怎么样你卡里的钱和小A卡里的钱的总和是不变的。）
* **隔离性**：指在并发的事务是相互隔离的。即一个事务的内部操作及正在操作的数据必须被封锁起来，不会被其他的事务来企图修改。
* **持久性**：持久性是指当数据库系统出现故障了，要确保已经提交的事务的更新是不会丢失的。即数据库中的数据的修改是永久性的。就算系统出现了故障，我们也可以使用数据库的备份和恢复来保证数据的修改。

#### 事务的隔离级别

* 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他事务中未提交事务修改的数据。（会出现脏读、不可重复读、幻读）

* 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 。（会出现不可重复读、幻读）

* 可重复读(Repeated Read)：可重复读。同一事务中所有的 查询均读取第 一次读取时已确定的快照，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读。（但是还存在幻象读，GAP可以解决幻读）

  目前仅表数据支持可重复读，表结构不支持可重复读（仅支持当前读），MySQL8.0已经将表结构放在innodb字典里了，也许以后支持表结构的可重复读。

* 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞，在事务中的任何时候所看到的数据都是事务启动时刻的状态，不论在这期间有没有其他事务已经修改了某些数据并提交。

  对于高并发应用来说，为了尽可能保证数据的一致性，自然是事务隔离级别越高越好。但是，隔离级别越低，事务请求的锁越少或保持锁的时间就越短，性能越好。虽然 Innodb 存储引擎默认的事务隔离级别是 REPEATABLE READ，但实际上在我们大部分的应用场景 下，都只需要 READ COMMITED 的事务隔离级别就可以满足需求了。

  **脏读** :一个事务读取到另一事务未提交的更新数据
  **不可重复读 **: 在同一事务中,多次读取同一数据返回的结果有所不同, 换句话说, 后续读取可以读到另一事务已提交的更新数据. 相反, “可重复读”在同一事务中多次读取数据时, 能够保证所读数据一样, 也就是后续读取不能读到另一事务已提交的更新数据。
  **幻读 **:一个事务读到另一个事务已提交的insert数据

#### 事务的机制

事务的机制是通过视图来实现的并发版本控制(MVCC), 不同的事务隔离级别创建读视图的时间点不同。

innodb的读提交和可重复读是用一致性视图实现，在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图；在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的；“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

#### 启动方式

1. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事物就启动了，而且并**不会自动提交**。这个事物持续存在直到你主动执行commit或rollback语句，或者断开连接；导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。

2. set autocommit=1，显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是rollback；事务开始时需要主动执行一次“begin”，多一次交互。

   START TRANSACTION 后，只有当commit数据才会生效，ROLLBACK后就会回滚；如果没有START TRANSACTION ，执行每个SQL自动提交，调用ROLLBACK是没有用的。

   begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一个操作innodb表的语句（第一个快照读），事务才真正启动。如果你想马上启动一个事务，可以使用start transaction with consistent snapshot这个命令。

3. 在set autocommit=1情况下，用begin启动事务，执行commit work and chain，则是提交事务并启动下一个事务，这样省去了再次执行begin语句的开销。

#### MVCC是怎么工作的

在可重复读隔离级别下，事务在启动的时候就拍了个快照，这个快照是基于整库的。

innodb里面每个事务有一个唯一的事务ID，叫做transaction id，它是在事务开始的时候向innodb事务系统申请的，按申请顺序严格递增。

每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。

按照可重复的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后执行期间，其他事物的更新对他不可见。

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见之外，有三种情况：

- 版本未提交，不可见
- 版本已提交，但是是在视图创建后提交的，不可见
- 版本已提交，而且在视图创建前提交的，可见

可重复读的核心就是一致性读；而事务中update更新数据都是先读后写的，这个读，只能读当前的值，成为当前读；此外，select查询语句加锁（加上lock in share mode或for update），也是当前读。

读提交与可重复读的主要区别：

- 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询共用这个一致性视图。
- 在读提交隔离级别下，每个语句执行前都会重新算出一个新的视图。



### 存储引擎

#### MyISAM和InnoDb区别

* innodb支持事务
* innodb支持外键
* innodb支持行锁
* myisam数据和索引分开放，innodb数据和索引放一起；
* 索引表：myisam叶子节点存放数据地址；innodb叶子节点存放真实的数据记录。（原因如上）
* myisam查询快，innodb写入快；

#### 为什么并发高时InnoDb写入快

* InnoDb支持行级锁，写入时只锁一行，myisam写入时会锁表
* 更新数据时，innodb只需要修改叶子节点，myisam需要修改索引结构（改动大）

#### 为什么MyISAM查询速度快（InnoDb维护的东西多）

* INNODB要缓存数据块，MYISAM只缓存索引块，这中间还有换进换出的减少
* innodb寻址要映射到块，再到行，MYISAM记录的直接是文件的OFFSET，定位比INNODB要快
* INNODB还需要维护MVCC一致；虽然你的场景没有，但他还是需要去检查和维护

#### Innodb行级锁和事务性，容易产生死锁，优化建议：

* 类似业务模块中，尽可能按照相同的访问顺序来访问，防止产生死锁;
* 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率
* 对于非常容易产生 锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率

#### InnoDB锁

**共享锁（s）**：又称读锁。允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。
**排他锁（Ｘ）**：又称写锁。允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。SELECT * FROM table_name WHERE ... FOR UPDATE。

* update,delete,insert都会自动给涉及到的数据加上排他锁，select语句默认不会加任何锁类型
* 加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制
* 如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁
* InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！
* 在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件
* 选择合理的事务大小，小事务发生锁冲突的几率也更小

#### RocksDB引擎

- rocksdb压缩率非常高，大约只有innodb的1/3，同时也要比压缩后的innodb小。
- rocksdb读性能对比innodb还是差不少，但是跟压缩后的innodb相比，某些场景下，还是有一定优势。
- 写入性能非常优秀。
- 非常适合写多读少，并且对容量比较敏感的业务场景，如日志系统。



### 索引

#### 常见模型

##### 哈希表

哈希表是一种以键-值（key-value）存储数据的结构，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。

多个key值经过哈希函数的换算，会出现同一个值的情况，处理这情况的方法是拉出一个链表；查找时，先定位到数组的位置，再去链表中顺序遍历。

key不是递增的，新增数据时速度快，只需往后追加，但缺点是，哈希索引做区间查询速度是很慢的，需要全部扫描。**哈希表适用于等值查询的场景**，比如memcached及一些NoSQL引擎。

##### 有序数组

数组根据唯一值按照递增顺序保存，无论查等值还是区间，用二分法查询，效率很高；仅看查询效率，有序数组是最好的数据结构了**有序数组在等值查询和范围查询场景中的性能都非常优秀**。

但是更新数据时，插入一条记录必须挪动后面的所有记录，成本太高。有序数据只适用于**静态存储引擎**，适合存放不会再修改的数据。

##### 树

h = log(m+1)N，m是数据块中数据项的个数，N是数据个数，h及查询次数，每一层的数据块中数据项是有顺序的（有序数组），全程使用二分查找；广泛应用于数据库引擎中。

#### innoDB的索引模型（B+树）

在InnoDB中，表都是根据主键顺序以索引的形式存放的，使用B+树索引模型，数据存放在B+树中。

根据叶子节点的内容，索引类型分为主键索引和非主键索引。

主键索引的叶子节点存放的是整行数据，在InnoDB中，主键索引又叫聚簇索引；

非主键索引的叶子节点内容是主键的值，在InnoDB中，非主键索引又叫二级索引；基于非主键索引的查询需要多扫描一课索引树，因此尽量使用主键查询。

如果查询的字段已经在二级索引树上，就不需要回表，可以直接提供结果；这个索引树覆盖了查询需求，称为覆盖索引；可以通过建立联合索引（冗余索引）来支持覆盖索引。

联合索引（a,b,c）实质是按a、b、c顺序拼接成二进制字节数组，索引记录是按该字节数组逐字节比较排序的。

##### B+树主键索引

主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小，从性能和空间方面看，自增主键是更好地选择。

适合业务字段直接做主键的场景：

1. 是有一个索引
2. 该索引是唯一索引

这就是典型的KV场景，由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

##### B+树页分裂

根据叶子节点结构，向上增加层数

https://www.cnblogs.com/qcfeng/p/6125465.html

##### 索引维护

索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，是的页面利用率更高；所以单重建二级索引可以省空间，但是重建主键索引会将整个表重建（同时影响其他索引，之后还得重建这些二级索引），可以直接使用：alter table T engine=InnoDB，重构所有索引。

truncate也可以清空索引空间，业务接受情况下可以代替delete。

##### 最左前缀原则

最左前缀可以是联合索引最左N个字段，也可以是最左m个字符。

当即有(a,b)联合查询，又有单独查询时，在空间考虑原则下，可以给小的字段创建一个单字段索引，再根据情况调整联合索引字段顺序。

##### 索引下推

使用联合索引时查询时，最左前缀可以定位记录，使用范围查询时（like、>=、<=等，测试时不带=号好像不能下推）时，范围查询字段后面的查询字段不符合最左前缀的要求：

在MySQL5.6之前，只能根据最左前缀查出匹配值后，一个个回表，从主键索引树找到数据行再比对后面查询的条件；

而MySQL5.6引入的索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。



### 锁

#### 全局锁

给整个数据库实例加锁。

- MySQL提供一种方法，命令是 Flush tables with read lock (**FTWRL**)，整个库处于只读状态，典型使用场景是做全库逻辑备份。

- 官方自带的逻辑备份工具是mysqldump，当mysqldump使用参数-signle-transaction的时候，导数据之前就会启动一个事物，确保拿到一致性视图。**一致性读**是好，但前提是引擎要支持这个隔离级别，这种方法只适用于所有的表使用事务引擎的库。(InnoDB库使用这种更好)

#### 表级锁

**表锁**：语法是 lock tables ... read/write。read会限制其他线程写操作，write会限制其他线程读操作。

**元数据锁(meta data lock，MDL)**：MySQL5.5引入了MDL，是为了防止DDL（操作表结构语句）和DML（增删改查）的冲突，不需要显示使用；当对一个表进行增删改查操作时，加MDL读锁，读锁之间不互斥，多个线程可以对同一数据表做增删改查（不可以是同一行）；当对表结构变更操作时，加MDL写锁，当表结构变成完成后才会执行其他线程。

#### 行锁

MySQL行锁是在各引擎层自己实现的，innoDB支持行锁，innodb行级锁是通过索引实现的，如果更新的列没建索引会锁整个表（根据主键索引逐行扫描 逐行加锁）。

在innodb事务中，行锁是在需要的时候加上去的，但并不是不需要了就立刻释放，而是要等到事务结束时才能释放，这个就是两阶段锁协议。

如果事务中需要锁多个行，要把最有可能造成索冲突、最影响并发度的锁尽量往后放。

#### 死锁

并发系统中，不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程进入无线等待的状态，称为死锁。

解决策略：

- 直接进入等待，直到超时。超时时间通过参数innodb_lock_wait_timeout来设置，默认值50s。
- 主动死锁检测，发现死锁后，主动回滚思索链条中的某一个事物，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑（默认是开启）。
- 控制并发

#### GAP间隙锁

当我们用范围条件而不是相等条件（唯一索引下）检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。（例：Repeatable Read隔离级别下，id列上有一个非唯一索引，对应SQL：delete from t1 where id = 10;符合条件的位置及前后可能插入新纪录的位置加GAP锁）。

间隙锁在InnoDB的唯一作用就是防止其它事务的插入操作，以此来达到防止幻读的发生，所以间隙锁不分什么共享锁与排它锁。

要禁止间隙锁的话，可以把隔离级别降为读已提交，或者开启参数innodb_locks_unsafe_for_binlog（在my.cnf里面的[mysqld]添加innodb_locks_unsafe_for_binlog = 1）。



### 优化

#### 数据库查询优化

* 永远用小结果集驱动大的结果集
* 只取出自己需要的 Columns
* 仅仅使用最有效的过滤条件
* 尽可能避免复杂的 Join 和子查询（减少锁表）,分解为几个小查询
* 使用count(*)获取行数效率高，count(列名)只记录非NULL的列
* like 'word%'可以用到缓存，'%word%'用不到缓存
* 分区partition by，分表分库

#### 建立索引原则

* 最左前缀匹配原则
* 尽量选择区分度高的列作为索引
* 索引列不能参与计算
* 尽量的扩展索引，不要新建索引
* 索引字段长度尽量的小
* 较频繁的作为查询条件的字段应该创建索引,更新非常频繁的字段不适合创建索引



### 架构

#### MySQL主从复制和读写分离

MySQL读写分离基本原理是让master数据库处理写操作，slave数据库处理读操作。master将写操作的变更同步到各个slave节点。MySQLProxy实际上是在客户端请求与MySQLServer之间建立了一个连接池。所有客户端请求都是发向MySQLProxy，然后经由MySQLProxy进行相应的分析，判断出是读操作还是写操作，分发至对应的MySQLServer上。对于多节点Slave集群，也可以起做到负载均衡的效果。

MySQL读写分离能提高系统性能的原因在于：

* 物理服务器增加，机器处理能力提升。拿硬件换性能。
* 主从只负责各自的读和写，极大程度缓解X锁和S锁争用。
* slave可以配置myisam引擎，提升查询性能以及节约系统开销。
* master直接写是并发的，slave通过主库发送来的binlog恢复数据是异步。
* slave可以单独设置一些参数来提升其读的性能。
* 增加冗余，提高可用性。

#### MySQL安全设置

* 定期做数据备份
* 不给root权限，合理安排权限
* 关闭远程访问
* 设置MySQL数据文件的权限

### 日常排查
mysql查看当前连接数：进入mysql命令行执行 show processlist; 可以显示前100条连接信息 show full processlist; 可以显示全部。随便说下，如果用普通账号登录，就只显示这用户的。
