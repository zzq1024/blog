# 第一节：MySQL奥义

### 基础

#### SQL执行流程

- 客户端
- 连接器（管理连接，权限验证）
- 查询缓存（命中则直接返回结果）
- 分析器（词法分析，语法分析）
- 优化器（执行计划生成，索引选择）
- 执行器（操作引擎，返回结果）
- 存储引擎（存储数据，提供读写接口）

#### char与varchar

* char和varchar 后面的长度表示的是字符的个数，而不是字节数。

* 如果某个数据表里的数据行的长度是可变的，那么，为了节约存储空间，MySQL会把这个数据表里的固定长度类型的数据列转换为相应的可变长度类型．例外：长度小于4个字符的char数据列不会被转换为varchar类型。

* 区别：
  * char 表示定长，长度固定，varchar表示变长，即长度可变
  * char最多能存放的**字符**个数 255，和编码无关；varchar最大有效长度是 65532 字节，在varchar存字符串的时候，第一个字节是空的，不存任何的数据，然后还需要两个字节（长度<255用一个字节存储长度，>255需要两个字节）来存放字符串的长度。所以有效长度就是 65535 - 1 - 2 = 65532字节，字符根据编码来定。
  * char的效率高，没有碎片，尤其更新比较频繁的时候，方便数据文件指针的操作，varchar更新数据需要重新计算长度
  * varchar相对来说比较灵活，可动态分配空间，char设置长度不合理时可能会浪费空间
* 如果已经对含有可变长度的表（varchar、blob、text）进行了很多更改，可以使用OPTIMIZE TABLE重新利用未使用的空间，并整理数据文件的碎片。

#### redo log与binlog

* redo log是innodb引擎提供的，binlog是mysql server自带的；
* redo log 记录 做了什么改动（比如把某个字段从0改成了1），binlog 记录 是怎么修改的（记录sql语句或者 记录更新前后的行）
* redo log 记录的，即使异常重启，都会刷新到磁盘（满血复活），而 bin log 记录的， 则主要用于备份
* Undo Log 的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为 Undo Log）

#### update语句的内部流程

mysql> update T set c=c+1 where id=2;

1.执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回；

2.执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据；

3.引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。

4.执行器生成这个操作的 binlog，并把 binlog 写入磁盘；

5.执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

#### change buffer

当需要更新一个数据页时，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性前提下，Innodb会将这些更新缓存到change buffer中，这样就不需要从磁盘中读这个数据页了。change buffer在内存中有拷贝也会被写入磁盘上。

使用场景：唯一索引不能使用change buffer，只有普通索引可以使用；写多读少的业务适用（如日志系统）

#### count

count()用于返回结果集的个数，如果count函数中参数为字段，会返回数据不为NULL的函数，因此尽量用count(*)、count(1)、count(主键ID)，count(1)要比count(主键ID)快，省去了每行ID对应值的解析；

效率排序：count(*)≈count(1)>count(主键ID)>count(字段)



### 事务

#### 特性

* **原子性**：事务中包含的程序作为数据库的逻辑工作单位，它对数据库中的数据进行操作时，要么全部执行，要么都不执行
* **一致性**：一个事务执行前和执行后，数据库都必须要处于一致性的状态。（你给小A的卡里转了500块，不管怎么样你卡里的钱和小A卡里的钱的总和是不变的。）
* **隔离性**：指在并发的事务是相互隔离的。即一个事务的内部操作及正在操作的数据必须被封锁起来，不会被其他的事务来企图修改。
* **持久性**：持久性是指当数据库系统出现故障了，要确保已经提交的事务的更新是不会丢失的。即数据库中的数据的修改是永久性的。就算系统出现了故障，我们也可以使用数据库的备份和恢复来保证数据的修改。

#### 事务的隔离级别

* 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他事务中未提交事务修改的数据。（会出现脏读、不可重复读、幻读）

* 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 。（会出现不可重复读、幻读）

  读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁（查询非索引字段时，逐行加锁），在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交

* 可重复读(Repeated Read)：可重复读。同一事务中所有的 查询均读取第 一次读取时已确定的快照，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读。（但是还存在幻象读，GAP可以解决幻读）

  目前仅表数据支持可重复读，表结构不支持可重复读（仅支持当前读），MySQL8.0已经将表结构放在innodb字典里了，也许以后支持表结构的可重复读。

* 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞，在事务中的任何时候所看到的数据都是事务启动时刻的状态，不论在这期间有没有其他事务已经修改了某些数据并提交。

  对于高并发应用来说，为了尽可能保证数据的一致性，自然是事务隔离级别越高越好。但是，隔离级别越低，事务请求的锁越少或保持锁的时间就越短，性能越好。虽然 Innodb 存储引擎默认的事务隔离级别是 REPEATABLE READ，但实际上在我们大部分的应用场景 下，都只需要 READ COMMITED 的事务隔离级别就可以满足需求了。

  **脏读** :一个事务读取到另一事务未提交的更新数据
  **不可重复读 **: 在同一事务中,多次读取同一数据返回的结果有所不同, 换句话说, 后续读取可以读到另一事务已提交的更新数据. 相反, “可重复读”在同一事务中多次读取数据时, 能够保证所读数据一样, 也就是后续读取不能读到另一事务已提交的更新数据。
  **幻读 **:一个事务读到另一个事务已提交的insert数据

#### 事务的机制

事务的机制是通过视图来实现的并发版本控制(MVCC), 不同的事务隔离级别创建读视图的时间点不同。

innodb的读提交和可重复读是用一致性视图实现，在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图；在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的；“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

##### MySQL中，有两个视图的概念：

- 一个是view，它是用一个查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view……，他的查询方法与表一样。
- 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（读提交）和RR（可重复读）隔离级别的实现。

#### 启动方式

1. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事物就启动了，而且并**不会自动提交**。这个事物持续存在直到你主动执行commit或rollback语句，或者断开连接；导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。

2. set autocommit=1，显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是rollback；事务开始时需要主动执行一次“begin”，多一次交互。

   START TRANSACTION 后，只有当commit数据才会生效，ROLLBACK后就会回滚；如果没有START TRANSACTION ，执行每个SQL自动提交，调用ROLLBACK是没有用的。

   begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一个操作innodb表的语句（第一个快照读），事务才真正启动。如果你想马上启动一个事务，可以使用start transaction with consistent snapshot这个命令。

3. 在set autocommit=1情况下，用begin启动事务，执行commit work and chain，则是提交事务并启动下一个事务，这样省去了再次执行begin语句的开销。

#### MVCC是怎么工作的

在可重复读隔离级别下，事务在启动的时候就拍了个快照，这个快照是基于整库的。

innodb里面每个事务有一个唯一的事务ID，叫做transaction id，它是在事务开始的时候向innodb事务系统申请的，按申请顺序严格递增。

每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。

按照可重复的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后执行期间，其他事物的更新对他不可见。

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见之外，有三种情况：

- 版本未提交，不可见
- 版本已提交，但是是在视图创建后提交的，不可见
- 版本已提交，而且在视图创建前提交的，可见

可重复读的核心就是一致性读；而事务中update更新数据都是先读后写的，这个读，只能读当前的值，成为当前读；此外，select查询语句加锁（加上lock in share mode或for update），也是当前读。

读提交与可重复读的主要区别：

- 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询共用这个一致性视图。
- 在读提交隔离级别下，每个语句执行前都会重新算出一个新的视图。



### 存储引擎

#### MyISAM和InnoDb区别

* innodb支持事务
* innodb支持外键
* innodb支持行锁
* myisam数据和索引分开放，innodb数据和索引放一起；
* 索引表：myisam叶子节点存放数据地址；innodb叶子节点存放真实的数据记录。（原因如上）
* myisam查询快，innodb写入快；

#### 为什么并发高时InnoDb写入快

* InnoDb支持行级锁，写入时只锁一行，myisam写入时会锁表
* 更新数据时，innodb只需要修改叶子节点，myisam需要修改索引结构（改动大）

#### 为什么MyISAM查询速度快（InnoDb维护的东西多）

* INNODB要缓存数据块，MYISAM只缓存索引块，这中间还有换进换出的减少
* innodb寻址要映射到块，再到行，MYISAM记录的直接是文件的OFFSET，定位比INNODB要快
* INNODB还需要维护MVCC（多版本并发控制）一致；

#### Innodb行级锁和事务性，容易产生死锁，优化建议：

* 类似业务模块中，尽可能按照相同的访问顺序来访问，防止产生死锁;
* 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率
* 对于非常容易产生 锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率

#### RocksDB引擎

- rocksdb压缩率非常高，大约只有innodb的1/3，同时也要比压缩后的innodb小。
- rocksdb读性能对比innodb还是差不少，但是跟压缩后的innodb相比，某些场景下，还是有一定优势。
- 写入性能非常优秀。
- 非常适合写多读少，并且对容量比较敏感的业务场景，如日志系统。



### 索引

#### 常见模型

##### 哈希表

哈希表是一种以键-值（key-value）存储数据的结构，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。

多个key值经过哈希函数的换算，会出现同一个值的情况，处理这情况的方法是拉出一个链表；查找时，先定位到数组的位置，再去链表中顺序遍历。

key不是递增的，新增数据时速度快，只需往后追加，但缺点是，哈希索引做区间查询速度是很慢的，需要全部扫描。**哈希表适用于等值查询的场景**，比如memcached及一些NoSQL引擎。

##### 有序数组

数组根据唯一值按照递增顺序保存，无论查等值还是区间，用二分法查询，效率很高；仅看查询效率，有序数组是最好的数据结构了**有序数组在等值查询和范围查询场景中的性能都非常优秀**。

但是更新数据时，插入一条记录必须挪动后面的所有记录，成本太高。有序数据只适用于**静态存储引擎**，适合存放不会再修改的数据。

##### 树

h = log(m+1)N，m是数据块中数据项的个数，N是数据个数，h及查询次数，每一层的数据块中数据项是有顺序的（有序数组），全程使用二分查找；广泛应用于数据库引擎中。

#### innoDB的索引模型（B+树）
- 叶子结点：存储实际记录行，记录行比较紧密的存储，适合大数据量**磁盘存储**；
- 非叶子节点：不存储实际记录，只存储索引，用于查询加速，适合**内存存储**；

在InnoDB中，表都是根据主键顺序以索引的形式存放的，使用B+树索引模型，数据存放在B+树中。

根据叶子节点的内容，索引类型分为主键索引和非主键索引。

主键索引的叶子节点存放的是整行数据，在InnoDB中，主键索引又叫聚簇索引；如果表没有定义主键，则第一个非空unique列是主键索引，否则，InnoDB会创建一个隐藏的row-id作为主键索引。

非主键索引的叶子节点内容是主键的值，在InnoDB中，非主键索引又叫二级索引；基于非主键索引的查询需要多扫描一课索引树，因此尽量使用主键查询。

如果查询的字段已经在二级索引树上，就不需要回表，可以直接提供结果；这个索引树覆盖了查询需求，称为覆盖索引；可以通过建立联合索引（冗余索引）来支持覆盖索引。

联合索引（a,b,c）实质是按a、b、c顺序拼接成二进制字节数组，索引记录是按该字节数组逐字节比较排序的。

可以使用某个字段前N个字节index_field(N)设置为索引，使用前缀索引，定义好长度，就可以做到即可以节省空间，又不用额外增加太多的查询成本；但是使用前缀索引需要回表判断字段的值是否相等，不能使用覆盖索引。

##### B+树主键索引

主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小，从性能和空间方面看，自增主键是更好地选择。

适合业务字段直接做主键的场景：

1. 只有一个索引
2. 该索引是唯一索引

这就是典型的KV场景，由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

##### B+树页分裂

根据叶子节点结构，向上增加层数

https://www.cnblogs.com/qcfeng/p/6125465.html

##### 索引维护

索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，是的页面利用率更高；所以单重建二级索引可以省空间，但是重建主键索引会将整个表重建（同时影响其他索引，之后还得重建这些二级索引），可以直接使用：alter table T engine=InnoDB，重构所有索引。

truncate也可以清空索引空间，业务接受情况下可以代替delete。

##### 最左前缀原则

最左前缀可以是联合索引最左N个字段，也可以是最左m个字符。

当即有(a,b)联合查询，又有单独查询时，在空间考虑原则下，可以给小的字段创建一个单字段索引，再根据情况调整联合索引字段顺序。

##### 索引下推

使用联合索引时查询时，最左前缀可以定位记录，使用范围查询时（like、>=、<=等，测试时不带=号好像不能下推）时，范围查询字段后面的查询字段不符合最左前缀的要求：

在MySQL5.6之前，只能根据最左前缀查出匹配值后，一个个回表，从主键索引树找到数据行再比对后面查询的条件；

而MySQL5.6引入的索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

#### 什么情况下有索引，但用不上

1.条件中有or（部分条件带索引），如：select * from user where id=2 or name='zzq'，name无索引

2.组合索引，查询条件是后边字段，如：index(name,age)，select * from user where age=20

3.like查询以%开头（以%结尾可以用）

4.**对索引字段做函数操作，可能会破坏索引值的有序性，不会走索引（参数可以用函数）**

查询条件存在隐形转换，如：number varchar(10)，select * from user where number=123；注意由于MySQL规则将字符串转化为数据进行比较，对于优化器这个语句会成为select * from user where CAST(number AS signed int)=123；但是select * from user where id='2'会走索引，select * from user where id='2'（优化器转化为select * from user where id=CAST('2' AS signed int);）

5.如果数据特别少，MySQL优化器估计全表扫描更快，就不会走索引。



### 锁

#### 全局锁

给整个数据库实例加锁。

- MySQL提供一种方法，命令是 Flush tables with read lock (**FTWRL**)，整个库处于只读状态，典型使用场景是做全库逻辑备份。

- 官方自带的逻辑备份工具是mysqldump，当mysqldump使用参数-signle-transaction的时候，导数据之前就会启动一个事物，确保拿到一致性视图。**一致性读**是好，但前提是引擎要支持这个隔离级别，这种方法只适用于所有的表使用事务引擎的库。(InnoDB库使用这种更好)

#### 表级锁

##### 表锁
语法是 lock tables ... read/write。read会限制其他线程写操作，write会限制其他线程读操作。

##### 元数据锁(meta data lock，MDL)
MySQL5.5引入了MDL，是为了防止DDL（操作表结构语句）和DML（增删改查）的冲突，不需要显示使用；当对一个表进行增删改查操作时，加MDL读锁，读锁之间不互斥，多个线程可以对同一数据表做增删改查（不可以是同一行）；当对表结构变更操作时，加MDL写锁，当表结构变成完成后才会执行其他线程。

##### 意向共享锁（IS）
预示着事务有意向对表中某些行加共享锁（协议：事务要获得行的共享锁，必须先获得表的IS锁），意向锁之间不互斥，IS会与排它锁互斥
SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE，要设置IS锁

##### 意向排它锁（IX）
预示着事务有意向对表中某些行加排它锁（协议：事务要获得行的排它锁，必须先获得表的IX锁），意向锁之间不互斥，IX会与意向锁、排它锁互斥
SELECT * FROM table_name WHERE ... FOR UPDATE，要设置IX锁

##### 自增锁
自增锁是一个特殊的表级别锁，专门针对事务插入AUTO_INCREMENT类型的列（自增主键），最简单的情况，如果一个事物正在插入记录，所有其他事务的插入必须等待，以便第一个事务多次插入是连续的主键值。

#### 行锁

MySQL行锁是在各引擎层自己实现的，innoDB支持行锁，innodb行级锁是通过索引实现的；如果更新的列没建索引会锁整个表（根据主键索引逐行扫描 逐行加锁）。

session：select * from t where c=5 for update; 在 Read Committed 隔离级别下，会锁上聚簇索引中的所有记录（先锁所有记录，然后回server层判断，释放c!=5的行锁）；在 Repeatable Read 隔离级别下，会锁上聚簇索引中的所有记录(锁住所有行并不会释放)，并且会锁上聚簇索引内的所有 GAP；

在innodb事务中，行锁是在需要的时候加上去的，但并不是不需要了就立刻释放，而是要等到事务结束时才能释放，这个就是两阶段锁协议。

如果事务中需要锁多个行，要把最有可能造成索冲突、最影响并发度的锁尽量往后放。

##### 共享锁（s）
又称读锁。允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。
##### 排他锁（Ｘ）
又称写锁。允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。SELECT * FROM table_name WHERE ... FOR UPDATE。

- update,delete,insert都会自动给涉及到的数据加上排他锁，select语句默认不会加任何锁类型
- 加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制
- select通过for update和lock in share mode读数据是当前读，读取当前最新数据；普通select是快照读，读取历史的快照，可提高并发。
- 如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁
- InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！
- 在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件
- 选择合理的事务大小，小事务发生锁冲突的几率也更小

#### GAP间隙锁

当我们用范围条件而不是相等条件（唯一索引下）检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。（例：select * from  user where user_id > 100 for update;他会给符合条件不存在的记录加锁，insert into user values(102,'name')会被锁住）。

跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作，间隙锁之间不存在冲突关系。

间隙锁在InnoDB的唯一作用就是防止其它事务的插入操作，以此来达到**防止幻读**的发生，所以间隙锁不分什么共享锁与排它锁。

间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。

间隙锁是在**可重复读隔离**级别下才会生效的，要禁止间隙锁的话，可以把隔离级别降为读已提交，或者开启参数innodb_locks_unsafe_for_binlog（在my.cnf里面的[mysqld]添加innodb_locks_unsafe_for_binlog = 1）。

##### 插入意向锁
多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此，可以提供插入并发。

#### 临键锁(Next-Key Locks)
临键锁，是行锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间；临键锁会封锁索引记录本身，以及索引记录之前的区间

#### next-key lock

间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。

如果数据表中已存在ID（0,5,10,15,10,25），select * from t for update会把整个表锁起来，就形成了7个next-key lock，(-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。

#### 死锁

并发系统中，不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程进入无线等待的状态，称为死锁。

解决策略：

- 直接进入等待，直到超时。超时时间通过参数innodb_lock_wait_timeout来设置，默认值50s。
- 主动死锁检测，发现死锁后，主动回滚思索链条中的某一个事物，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑（默认是开启）。
- 控制并发



### 优化器

优化器选择索引的目的，是找一个最优的执行方案，用最小的代价执行语句。判断标准有：扫描行数、是否使用临时表、是否排序等。

扫描行数根据索引上不同值的个数（基数）决定。

当扫描行数信息不对时，可以使用analyze table t命令，来重新统计索引信息。

用explain查看优化器用错索引时，可以使用force index进行强行指定索引，也可以通过修改sql语句来优化，也可以增加或删除索引绕过这个问题。



### 优化

#### 数据库查询优化

* 永远用小结果集驱动大的结果集
* 只取出自己需要的 Columns
* 仅仅使用最有效的过滤条件
* 尽可能避免复杂的 Join 和子查询（减少锁表）,分解为几个小查询
* 使用count(*)获取行数效率高，count(列名)只记录非NULL的列
* like 'word%'可以用到索引，'%word%'用不到索引
* 分区partition by，分表分库

#### 建立索引原则

* 最左前缀匹配原则
* 尽量选择区分度高的列作为索引
* 索引列不能参与计算
* 尽量的扩展索引，不要新建索引
* 索引字段长度尽量的小
* 较频繁的作为查询条件的字段应该创建索引,更新非常频繁的字段不适合创建索引

#### 字符串索引优化

- 直接创建完整索引，这样可能比较占用空间

- 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引

- 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题

- 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。


### 架构

#### MySQL主从复制和读写分离

MySQL读写分离基本原理是让master数据库处理写操作，slave数据库处理读操作。master将写操作的变更同步到各个slave节点。MySQLProxy实际上是在客户端请求与MySQLServer之间建立了一个连接池。所有客户端请求都是发向MySQLProxy，然后经由MySQLProxy进行相应的分析，判断出是读操作还是写操作，分发至对应的MySQLServer上。对于多节点Slave集群，也可以起做到负载均衡的效果。

MySQL读写分离能提高系统性能的原因在于：

* 物理服务器增加，机器处理能力提升。拿硬件换性能。
* 主从只负责各自的读和写，极大程度缓解X锁和S锁争用。
* slave可以配置myisam引擎，提升查询性能以及节约系统开销。
* master直接写是并发的，slave通过主库发送来的binlog恢复数据是异步。
* slave可以单独设置一些参数来提升其读的性能。
* 增加冗余，提高可用性。



#### MySQL安全设置

* 定期做数据备份
* 不给root权限，合理安排权限
* 关闭远程访问
* 设置MySQL数据文件的权限



### 日常排查

mysql查看当前连接数：进入mysql命令行执行 show processlist; 可以显示前100条连接信息 show full processlist; 可以显示全部。随便说下，如果用普通账号登录，就只显示这用户的。



### 日常使用

#### 删除

- drop table命令，可以将.ibd（表数据文件）删除；
- delete命令只是把记录的位置或者数据页标记为“可复用”，但磁盘文件大小是不会变的，这时未使用的空间就是空洞；插入操作造成的页分裂也会产生空洞。
- alter table A engine=InnoDB命令可以重建表，对于很大的表来说，很消耗IO和CPU，要在业务低峰时使用；也可以建一个相同表结构的B表，将A表数据迁移到B后，业务逻辑再切到B表。

#### Online DDL的流程：

1.建立临时文件，扫描表A主键所有数据页

2.用表A的记录生成B+树，存在临时文件中

3.生成临时文件过程中，将A表的操作记录存于一个日志文件中

4.临时文件生成后，将日志文件应用到临时文件，得到逻辑结构上与表A相同的数据文件

5.用临时文件代替表A的数据文件

#### 重建表的不同方式

- 从MySQL5.6开始，alter table t engine=InnoDB（也就是recreate）默认就是以上的流程了
- analize table t 其实不是重建表，只是对表的索引重新统计，没有修改数据，这个过程加了MDL读锁
- optimize table t 等于 recreate+analize
- truncate可以理解为drop+create
