### 名词

QPS：每秒请求数

带宽（BPS）:每秒传输字节数

时延：一台机器ping另一台机器的时间

带宽时延积（BDP）：带宽 x 时延，约等于窗口的容量

吞吐量：窗口/时延

HTTP keepalive：将短连接做长连接复用；

TCP keepalive：检测实际断掉的连接并释放资源；心跳检测维持两端的活跃网络包；

### TCP、UDP区别

- TCP是**有连接的**，两台主机在进行数据交互之前**必须先通过三次握手**建立连接；而UDP是无连接的，没有建立连接这个过程
- TCP是**可靠的传输**，TCP协议通过确认、重传、滑动窗口、拥塞控制等机制来保证数据传输的可靠性；而UDP是不可靠的传输
- TCP保证数据顺序，UDP不保证。
- TCP是基于**字节流**的，将数据看做无结构的字节流进行传输，当应用程序交给TCP的数据长度太长，超过MSS时，TCP就会对数据进行分段，因此TCP的数据是无边界的；而UDP是**面向报文**的，无论应用程序交给UDP层多长的报文，UDP都不会对数据报进行任何拆分等处理，因此UDP保留了应用层数据的边界 

#### TCP创建连接时三次握手：

- 第一次握手，A的TCP客户进程也是首先创建传输控制块TCB，然后向B发出连接请求报文段，（首部的**同步位SYN=1**，**初始序号seq=x）**，（SYN=1的报文段不能携带数据）但要消耗掉一个序号，此时TCP客户进程进入SYN-SENT（同步已发送）状态。
- 第二次握手，B收到连接请求报文段后，如同意建立连接，则向A发送确认，在确认报文段中（**SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y**），测试TCP服务器进程进入SYN-RCVD（同步收到）状态；
- 第三次握手，TCP客户进程收到B的确认后，要向B给出确认报文段（**ACK=1，确认号ack=y+1，序号seq=x+1**）（初始为seq=x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。TCP连接已经建立，A进入ESTABLISHED（已建立连接）。B收到A的确认后，也进入ESTABLISHED状态；**注：第三次可以携带数据**

##### 为什么A还要发送一次确认呢？可以二次握手吗？

**主要为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误**。假设，A在最开始的时候发送了一段请求连接的报文，但是因为网络不好，在网络中滞留太久；A因为太久没有收到确认报文，以为B没有收到，然后又重新发了一份报文，结果这份成功了，然后建立了连接。可是在连接成功后，那一份在网络滞留的报文突然又好了，到达了B，导致服务器再次建立了连接，这样就导致了服务器的不必要错误和浪费资源。所以如果采用的是三次握手。就算那一份失效的报文重新又发送了，但是因为客户端不会再发送确认报文了，而服务端接收不到确认报文，就不会建立连接。

##### Server端易受到SYN攻击？

服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击，SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。

防范SYN攻击措施：降低主机的等待时间使主机尽快的释放半连接的占用，短时间受到某IP的重复SYN则丢弃后续请求。

#### TCP断开时的四次挥手：

- 第一次挥手，A的应用进程先向其TCP发出连接释放报文段（**FIN=1，序号seq=u**），并停止再发送数据，主动关闭TCP连接，进入FIN-WAIT-1（终止等待1）状态，等待B的确认。
- 第二次挥手，B收到连接释放报文段后即发出确认报文段，（**ACK=1，确认号ack=u+1，序号seq=v**），B进入CLOSE-WAIT（关闭等待）状态，此时的TCP处于半关闭状态，A到B的连接释放。此时，A收到B的确认后，进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。
- 第三次挥手，B没有要向A发出的数据，B发出连接释放报文段（**FIN=1，ACK=1，序号seq=w，确认号ack=u+1），**B进入LAST-ACK（最后确认）状态，等待A的确认。
- 第四次挥手，A收到B的连接释放报文段后，对此发出确认报文段（**ACK=1，seq=u+1，ack=w+1**），A进入TIME-WAIT（时间等待）状态。B收到确认报文段后进入**CLOSED状态**；此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，A才进入CLOSED状态

##### 为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态

**1.保证A发送的最后一个ACK报文能够到达B：**

这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，B超时重传FIN+ACK报文段，而A能在2MSL时间内收到这个重传的FIN+ACK报文段，接着A重传一次确认，重新启动2MSL计时器，最后A和B都进入到CLOSED状态，**若A在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到B重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则B无法正常进入到CLOSED状态。**

**2.防止“已失效的连接请求报文段”出现在本连接中**：

A在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段；例如：A 刚发出的数据包，能保持 MSL（最大分段寿命，TCP 分段可以存在于互联网系统中的最大时间） 时长的寿命，它到了 B 端后，B 端由于关闭连接了，会响应 RST 包，这个 RST 包最长也会在 MSL 时长后到达 A，那么 A 端只要保持 TIME_WAIT 到达 2MS 就能保证网络中这个连接的包都会消失。

##### TCP半开连接

TCP是全双工协议，意思是客户端和服务器都可以发送消息，此时也可以称为你说的完全连接。所谓半开，是指关闭连接时，不要调用close函数，而是调用shutdown，而且传递的参数是关闭写（关闭读不行），这样，相当于四次挥手中A只发出FIN并收到ACK，此时两端的状态分别是fin_wait2和close_wait。这种状态下，被动关闭端B仍然可以发送消息，而主动关闭端A就不行了，这就是半开连接。

#### TCP如何保证可靠传输

##### 检验和

通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。

##### 序列号/确认应答

只要发送端有一个包传输，接收端没有回应确认包（ACK包），都会重发。或者接收端的应答包，发送端没有收到（确认）也会重发数据，这就可以保证数据的完整性。

##### 超时重传

超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传；在重发的过程中，假如一个包经过多次的重发也没有收到对端的确认包，那么就会认为接收端异常，强制关闭连接。并且通知应用通信异常强行终止。

##### 滑动窗口控制（流量控制）

超时重传的机制存在效率低下的问题，前一个包确认之后，才能发送下一个包；

窗口的大小就是在无需等待确认包的情况下，发送端还能发送的最大数据量；TCP并不是每一个报文段都会回复ACK的，可能会对两个报文段发送一个ACK，也可能会对多个报文段发送1个ACK；这个机制的实现就是使用了大量的缓冲区，通过对多个段进行确认应答的功能，通过下一次的确认包可以判断接收端是否已经接收到了数据，如果已经接收了就从缓冲区里面删除数据；从而增加数据传输的速率提高应用的吞吐量；

接收端在没有收到自己所期望的序列号数据之前，会对之前的数据进行重复确认。发送端在收到某个应答包之后，又连续3次收到同样的应答包，则数据已经丢失了，需要重发。发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界；接收窗口只有在前面所有的段都确认的情况下才会移动左边界。

TCP维护了两个缓冲区：

- 发送方缓冲区：发送方缓冲区用于存储已经准备就绪数据和发送了但是没有被确认的数据
- 接收方缓冲区：接收方缓冲区用于存储已经被接收但是还没有被用户进程消费的数据

接收方窗口则是被接收缓冲区（大小取决于应用、系统、硬件的限制，TCP传输速率不能大于应用的数据处理速率）所影响的，如果数据没有被用户进程使用那么接收方通告的窗口就会相应得到减小，**发送窗口**取决于接收方窗口的大小，接收端可以根据自己的状况通告窗口大小，从而控制发送端的接收，进行流量控制。**可用窗口**的大小等于接收方窗口减去发送但是没有被确认的数据包大小。

##### 拥塞控制

发送方维护一个叫拥塞窗口cwnd的状态变量，其值取决于网络的拥塞程度，并且动态变化；

拥塞窗口的维护原则：只要网络没有出现拥塞，拥塞窗口就增大一些；只要网络出现拥塞，拥塞窗口就减少一些；

判断网络拥塞的依据：网络丢包（一种是超时重传RTO[Retransmission Timeout]超时，另一个是发送方收到三个重复确认ACK）；

发送方将拥塞窗口作为发送窗口，及拥塞窗口大小=发送窗口大小；

慢启动阈值ssthresh：

- 当cwnd<ssthresh，使用慢开始算法；
- 当cwnd >= ssthresh时，就会进入“拥塞避免算法”

###### 4种拥塞控制算法

拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）快重传，4）快恢复

- 慢启动

  每当收到一个ACK，cwnd大小加一；每当过了一个往返延迟时间RTT(Round-Trip Time)，cwnd大小直接翻倍，乘以2，呈指数让升；直到cwnd>=ssthresh，就会进入“拥塞避免算法”。

- 拥塞避免

  收到一个ACK，则cwnd = cwnd + 1 / cwnd；每当过了一个往返延迟时间RTT，cwnd大小加一。拥塞避免算法可以避免窗口增长过快导致窗口拥塞，而是缓慢的增加调整到网络的最佳值。

- 拥塞状态时的算法

  超时重传RTO[Retransmission Timeout]超时，TCP会重传数据包。TCP认为这种情况比较糟糕，会执行：

  - 由于发生丢包，将慢启动阈值ssthresh设置为当前cwnd的一半，即ssthresh = cwnd / 2.
  - cwnd重置为1
  - 进入慢启动过程

  最为早期的TCP Tahoe算法就只使用上述处理办法，但是由于一丢包就一切重来，导致cwnd又重置为1，十分不利于网络数据的稳定传递。

- 快重传

  TCP Reno算法进行了优化。当发送端接收到3个以上的重复ACK，TCP就意识到数据发生丢失，需要重传。这个机制不需要等到RTO超时，算法逻辑如下：

  - cwnd大小缩小为当前的一半
  - ssthresh设置为缩小后的cwnd大小
  - 然后进入快恢复算法

- 快恢复

  TCP Tahoe是早期的算法，所以没有快速恢复算法，而Reno算法有。在进入快速恢复之前，cwnd和ssthresh已经被更改为原有cwnd的一半。算法逻辑如下：

  - cwnd = cwnd + 3 *MSS，加3* MSS的原因是因为收到3个重复的ACK。
  - 重传指定的数据包。
  - 重传完成后，退出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法。

#### websocket

**Socket**是对TCP/IP协议的抽象，封装了应用层和传输控制层之间的一组接口，比如create、listen、connect、accept、send、read和write等等。
WebSocket protocol 是HTML5一种新的协议。它实现了浏览器与服务器全双工通信(full-duplex)。一开始的握手需要借助HTTP请求完成。WebSocket同HTTP一样也是应用层的协议，但是它是一种双向通信协议，是建立在TCP之上的。

目的：即时通讯，替代轮询。

### DNS

#### dns使用什么协议传输

DNS在进行区域传输的时候使用TCP协议，其它时候则使用UDP协议； 

区域传输：DNS的规范规定了2种类型的DNS服务器，一个叫主DNS服务器，一个叫辅助DNS服务器。在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫做区传送。

**区域传送时使用TCP原因**：

1.辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多；

2.TCP是一种可靠的连接，保证了数据的准确性；

**域名解析时使用UDP协议**：

客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器负载更低，响应更快

#### DNS查询

##### DNS查询方式

- 递归查询：本机向本地域名服务器发出一次查询请求，就静待最终的结果。如果本地域名服务器无法解析，自己会以DNS客户机的身份向其它域名服务器查询，直到得到最终的IP地址告诉本机；
- 迭代查询：本地域名服务器向根域名服务器查询，根域名服务器告诉它下一步到哪里去查询，然后它再去查，每次它都是以客户机的身份去各个服务器查询。
- **域名服务器之间的查询使用迭代查询方式，以免根域名服务器的压力过大**

##### 域名解析过程

1.首先搜索**浏览器的 DNS 缓存**，缓存中维护一张域名与 IP 地址的对应表；

2.若没有命中，则继续搜索**操作系统的 DNS 缓存**；

3.若仍然没有命中，则操作系统将域名发送至**本地域名服务器**，本地域名服务器查询自己的 DNS 缓存，查找成功则返回结果（注意：主机和本地域名服务器之间的查询方式是**递归查询**）；

4.若本地域名服务器的 DNS 缓存没有命中，则本地域名服务器向上级域名服务器进行查询，通过以下方式进行**迭代查询**（注意：本地域名服务器和其他域名服务器之间的查询方式是迭代查询，防止根域名服务器压力过大）：

- 首先本地域名服务器向**根域名服务器**发起请求，根域名服务器是最高层次的，它不会直接指明这个域名对应的 IP 地址，而是返回顶级域名服务器的地址，也就是说给本地域名服务器指明一条道路，让他去这里寻找答案
- 本地域名服务器拿到这个**顶级域名服务器**的地址后，就向其发起请求，获取**权限域名服务器**的地址
- 本地域名服务器根据权限域名服务器的地址向其发起请求，最终得到该域名对应的 IP 地址

5.本地域名服务器将得到的 IP 地址返回给操作系统，同时自己将 IP 地址缓存起来

6.操作系统将 IP 地址返回给浏览器，同时自己也将 IP 地址缓存起来

7.浏览器就得到了域名对应的 IP 地址，并将 IP 地址缓存起来

### 同步&异步与阻塞&非阻塞

#### 同步&异步

同步 指进程 调用接口时 需要等待接口处理完数据并相应进程才能继续执行。这里重点是数据处理完成 并返回。

异步 指进程调用接口后，不必等待数据准备完成 可以继续执行。后续数据准备好通过一定的方式获得 例如回调；这里重点是 服务器也必须支持异步操作。不然没法返回数据。

同步异步针对的是 如果接收不到数据 当前代码逻辑的状态。

#### 阻塞&非阻塞

阻塞 指的是 进程调用接口后 如果接口没有准备好数据，那么这个进程会被挂起 什么也不能做，直到有数据返回时唤醒。 

非阻塞 就是进程调用接口后 如果接口没有准备好数据，进程也能处理后续的操作，但是需要不断的去轮询检查 数据是否已经处理完成。

阻塞非阻塞针对的是 如果接收不到数据 当前进程的状态。



### 网络IO模型

对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：

1.等待数据准备 (Waiting for the data to be ready)

2.将数据从内核拷贝到进程中(Copying the data from the kernel to the process)

#### 阻塞IO（blocking IO）

在linux中，默认情况下所有的socket都是blocking，当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。

**blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。**

一个简单的改进方案是在服务器端使用**多线程（或多进程）**，多线程（或多进程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。具体使用多进程还是多线程，并没有一个特定的模式。**传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户机提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的CPU资源，譬如需要进行大规模或长时间的数据运算或文件访问，则进程较为安全。**通常，使用pthread_create ()创建新线程，fork()创建新进程。

如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而线程与进程本身也更容易进入假死状态。这时可能会考虑使用**“线程池”或“连接池”**，“线程池”旨在减少创建和销毁线程的频率，“连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。**所谓“池”始终有其上限，当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有池的时候效果好多少**。

#### **非阻塞IO（non-blocking IO**）

Linux下，可以通过设置socket使其变为non-blocking，**在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有，服务器线程可以通过循环调用recv()接口，可以在单个线程内实现对所有连接的数据接收工作。但是上述模型绝不被推荐。因为，循环调用recv()将大幅度推高CPU 占用率；此外，在这个方案中recv()更多的是起到检测“操作是否完成”的作用**。

non-blocking IO在执行recvfrom这个系统调用的时候，如果kernel的数据没有准备好，这时候不会block进程。但是当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内进程是被block的。

#### 多路复用IO（IO multiplexing）

**select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO**。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。

多路复用IO需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。**使用select以后最大的优势是用户可以在一个线程内同时处理多个socket的IO请求，用户可以注册多个socket，然后不断地调用select读取被激活的socket，即可达到在同一个线程内同时处理多个IO请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。（多说一句：所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）**

在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。因此select()与非阻塞IO类似。

相比其他模型，使用select() 的事件驱动模型只用单线程（进程）执行，占用资源少，不消耗太多 CPU，同时能够为多客户端提供服务。当需要探测的句柄值较大时，select()接口本身需要消耗大量时间去轮询各个句柄，linux提供了epoll更为高效的接口（遗憾的是不同的操作系统特供的epoll接口有很大差异，所以使用类似于epoll的接口实现具有较好跨平台能力的服务器会比较困难）。

##### IO多路复用的机制select，poll，epoll：

- **select**：本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理，单个进程可监视的fd数量被限制，即能监听端口的大小有限，32位机默认是1024个。64位机默认是2048；对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低；需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大；
- **poll**：poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。**它没有最大连接数的限制**，原因是它是基于链表来存储的。
- **epoll**：没有最大并发连接的限制；不会随着FD数目的增加效率下降，只有活跃可用的FD才会调用callback函数；内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。epoll用到红黑树和链表结构，红黑树是事件全集，包括不活跃事件（等待复用的空闲连接），相当于链表的字典，用于快速查询；链表中存放的是活跃的事件，网卡收到报文形成活跃事件，放入该链表；当需要监控某个事件时，用户进程要把它加到树中；当某个事件发生时，系统把它加入到链表中。

#### 异步IO（Asynchronous I/O）

**异步IO是真正非阻塞的**，它不会对请求进程产生任何的阻塞，用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

#### IO模型总结

调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还在准备数据的情况下会立刻返回。 

synchronous IO做”IO operation”的时候会将process阻塞，blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO；asynchronous IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。

### 网络拥塞

#### 原因

网络中存在瓶颈，该瓶颈的吞吐量小于节点单位时间发送的数据量；接收缓冲空间大于瓶颈处可用缓冲空间；

超量的数据无法从瓶颈路径发送，只好在缓存区排队，而缓冲区的大小有限制，积压的数据量超出缓存区大小，就会发生丢弃。

#### 恢复

基于丢包：超时重传对吞吐量的影响比较大，因为大量超时重传已明确表明网络瓶颈处发生了拥塞，发送方一般会将发送窗口降到一个相当低的值，重新缓慢增长发送窗口，以避免更严重的拥塞发生。高延迟的网络中发送窗口增长更加缓慢，少量的超时重传都会对吞吐量造成显著影响。因此多数TCP的拥塞避免算法会尽量避免超时重传，或减轻超时重传的影响。

基于延时：TCP vegas 里面的主要思想就是通过观察RTT的变化来判断当前网络是比较畅通还是比较拥堵，理由是持续增长的RTT被认为是发生拥塞的先兆；并规定diff的上限下限，作为判断当前网络状况的参考。当diff 大于上限时发送方主动减小发送窗口，当diff 小于下限时，发送方适当增加发送窗口。