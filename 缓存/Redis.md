# 第一节：Redis

### 基础

#### Redis如何淘汰过期的keys

Redis keys过期有两种方式：被动和主动方式。
当一些客户端尝试访问它时，key会被发现并主动的过期。
当然，这样是不够的，因为有些过期的keys，永远不会访问他们。 无论如何，这些keys应该过期，所以定时随机测试设置keys的过期时间。所有这些过期的keys将会从密钥空间删除。

##### 惰性删除策略

当一个数据的过期时间到了以后，并不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据。

**主库**：客户端从主库上读取留存的过期数据，主库会触发删除操作，此时，客户端并不会读到过期数据。

**从库**： Redis 3.2 之前的版本，从库在服务读请求时，并不会判断数据是否过期，而是会返回过期数据。在 3.2 版本后，Redis 做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。

##### 定期删除策略

Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存

#### 单线程

Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程；Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

##### Redis为什么使用单线程

多线程下，共享资源并发访问时，需要加锁控制，并行变串行，没有提高效率，还增加了额外开销；所以Redis直接使用单线程；

##### 单线程的Redis为什么那么快

- Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因；

- Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率；

  - 基本IO模型阻塞点，当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。

  - Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，可以处理其他请求，不用一直等待。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性；为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。

##### Redis单线程处理IO请求性能瓶颈

- 任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：

  - **操作bigkey**：写入一个bigkey在分配内存时需要消耗更多的时间，删除bigkey释放内存同样会产生耗时；
  - **使用复杂度过高的命令**：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；
  - **淘汰策略**：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；
  - **AOF刷盘开启always机制**：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；
  - **主从全量同步生成RDB**：虽然采用fork子进程生成数据快照，但**fork**这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；

  **优化：**针对bigkey问题，Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。

- 并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。

  **优化：**Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。

#### Redis内存回收

高版本的Redis中当内存达到极限时，内存淘汰策略主要采用了6种方式进行内存对象的释放操作：

- volatile-lru:从设置了过期时间的数据集中，选择最近最久未使用的数据释放
- allkeys-lru:从数据集中(包括设置过期时间以及未设置过期时间的数据集中)，选择最近最久未使用的数据释放
- volatile-random:从设置了过期时间的数据集中，随机选择一个数据进行释放
- allkeys-random:从数据集中(包括了设置过期时间以及未设置过期时间)随机选择一个数据进行入释放
- volatile-ttl：从设置了过期时间的数据集中，选择马上就要过期的数据进行释放操作
- noeviction：不删除任意数据(但redis还会根据引用计数器进行释放),这时如果内存不够时，会直接返回错误

默认的内存策略是noeviction [redis.conf：maxmemory-policy noeviction]

#### Redis持久化

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.
  - 命令：使用 save 或者 bgsave，来生成 RDB 文件；save：在主线程中执行，会导致阻塞；bgsave：创建一个子进程（可以共享主线程的所有内存数据），专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。
  - 生成快照：bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件；如果主线程要修改一块数据（键值对 C），那么这块数据就会被复制一份，生成该数据的副本（键值对 C’），主线程在这个数据副本上进行修改，同时，bgsave 子进程可以继续把原来的数据（键值对 C）写入 RDB 文件。这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。
  - 频繁执行全量快照，也会带来两方面开销：一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力；另一方面，虽然子进程在创建后不会再阻塞主线程，但是，fork 子进程的操作过程会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程）；
  - 为避免频繁将全量数据写入磁盘，我们可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。
  - Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。
- AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。其中有三种写日志策略：
  - Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
  - Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
  - No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘；

#### 缓存失效

- 缓存雪崩

  - 原因1：缓存中有大量数据同时过期，导致大量请求发送给数据库；

    解决方案：1.给数据的过期时间增加一个较小的随机数，避免数据同时过期；2.非核心数据，停止从缓存中查数据，直接返回预定义的信息；核心数据，继续从数据库中获取；

  - 原因2：Redis实例发生故障夯机，无法处理请求，这就会导致大量请求一下子积压到数据库层；

    解决方案：限制redis请求数

- 缓存击穿：

  - 原因：热点数据失效，访问该数据的大量请求，都发送到了后端数据库；

    解决方案：热点数据不设置过期时间；

- 缓存穿透：

  - 原因：指访问的数据既不在缓存，也不在数据库，导致大量持续的无效请求；

    解决方案：1.缓存空值或缺省值；2.使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。3.在请求入口处，检查合法性

#### 布隆过滤器

布隆过滤器本质是一个**位数组**，位数组就是数组的每个元素都只占用 1 bit ，每个元素只能是 0 或者 1；除此，布隆过滤器除了一个位数组，还有 K 个哈希函数；当一个元素加入布隆过滤器中的时候，会进行如下操作：

- 使用 K 个哈希函数对元素值进行 K 次计算，得到 K 个哈希值
- 根据得到的哈希值，对 位数组的长度取模，在位数组中把对应下标的值置为 1

当要判断一个值是否在布隆过滤器中，对元素再次进行哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

当插入的元素原来越多，位数组中被置为 1 的位置就越多，当一个不在布隆过滤器中的元素，经过哈希计算之后，得到的值在位数组中查询，有可能这些位置也都被置为 1。这样一个不存在布隆过滤器中的也有可能被误判成在布隆过滤器中。但是如果布隆过滤器判断说一个元素不在布隆过滤器中，那么这个值就一定不在布隆过滤器中。简单来说：

- 布隆过滤器说某个元素在，可能会被误判。
- 布隆过滤器说某个元素不在，那么一定不在。
- 传统的布隆过滤器并不支持删除操作

#### 数据类型及底层数据结构
Redis中的一个对象的结构体表示如下：
```c
typedef struct redisObject {  
    // 数据类型  
    unsigned type:4;         
    // 编码方式  
    unsigned encoding: 4;  
    // 引用计数  
    int refcount;  
    // 指向对象的值  
    void *ptr;  
} robj;
```

type数据类型包括：
- REDIS_STRING	字符串对象
- REDIS_LIST	列表对象
- REDIS_HASH	哈希对象
- REDIS_SET	集合对象
- REDIS_ZSET	有序集合对象

Redis对象底层数据结构:
- REDIS_ENCODING_INT	long 类型的整数
- REDIS_ENCODING_EMBSTR	embstr 编码的简单动态字符串
- REDIS_ENCODING_RAW	简单动态字符串
- REDIS_ENCODING_HT	字典
- REDIS_ENCODING_LINKEDLIST	双端链表
- REDIS_ENCODING_ZIPLIST	压缩列表
- REDIS_ENCODING_INTSET	整数集合
- REDIS_ENCODING_SKIPLIST	跳跃表和字典

##### String（字符串）

字符串类型实际上可以是字符串（简单的字符串、复杂的字符串（xml、json）、数字（整数、浮点数）、二进制（图片、音频、视频）），但最大不能超过512M；

应用：缓存功能；计数器；共享session；频率限制；

数据结构：如果一个String类型的value能够保存为整数，则将对应redisObject 对象的encoding修改为REDIS_ENCODING_INT（整数存储）；如果不能转为整数,用字符串存储，embstr和raw两种。embstr应该是Redis 3.0新增的数据结构，如果字符串对象的长度小于39字节，就用embstr对象，否则用传统的raw对象。
embstr优点：
1.embstr的创建只需分配一次内存，而raw为两次（一次为sds分配对象，另一次为objet分配对象，embstr省去了第一次）。
2.相对地，释放内存的次数也由两次变为一次。
3.embstr的objet和sds放在一起，更好地利用缓存带来的优势。

##### Hash（哈希）

Hash是一个string类型的field和value的映射表（键值对）；

应用：hash特别适合用于存储对象，可以Hash数据结构来存储用户信息，商品信息等等。

数据结构：创建新的Hash类型时，默认也使用**压缩列表**存储value（节约内存），保存数据过多时，使用**hash table**。
ziplist中的哈希对象是按照key1,value1,key2,value2这样的顺序存放来存储的。当对象数目不多且内容不大时，这种方式效率是很高的。
hashtable的是由dict这个结构来实现的, dict是一个字典，其中的指针dicht ht[2] 指向了两个哈希表，dicht[0] 是用于真正存放数据，dicht[1]一般在哈希表元素过多进行rehash的时候用于中转数据，dictht中的table用于真正存放元素了，每个key/value对用一个dictEntry（链表）表示，放在dictEntry数组中。

##### List（列表）

可以队列表两端插入（pubsh）和弹出（pop），还可以获取指定范围的元素列表、获取指定索引下表的元素等，列表是一种比较灵活的数据结构，它可以充当栈和队列的角色，list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

应用：文章列表；关注列表；栈、队列；消息队列（不建议）；

数据结构：当创建新的列表时，默认是使用**压缩列表**作为底层数据结构的，当list内容较多时，使用**双向链表**。
压缩列表能够节省内存空间，因为它所存储的内容都是在连续的内存区域当中的，当列表对象元素不大，每个元素也不大的时候，就采用ziplist存储，但当数据量过大时就ziplist就不是那么好用了；因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。
双向链表结构比较简单，节点中存放pre和next两个指针，还有节点相关的信息，当每增加一个node的时候，就需要重新malloc一块内存。

##### Set（集合）

集合类型也是用来保存多个字符串的，但和列表不同的是集合中不允许有重复的元素，并且集合中的元素是无序的，不能通过索引下标获取元素，redis除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集；

应用：标签；随机数；微博共同关注、共同喜好

数据结构：创建Set类型的key-value时，如果value能够表示为整数，则使用**intset**(整形数组)类型保存value。数据量大时，切换为使用**hash table**保存各个value。
intset是一个有序集合，查找元素的复杂度为O(logN)，但插入时不一定为O(logN)，因为有可能涉及到升级操作，比如当集合里全是int16_t型的整数，这时要插入一个int32_t，那么为了维持集合中数据类型的一致，那么所有的数据都会被转换成int32_t类型，涉及到内存的重新分配，这时插入的复杂度就为O(N)了，intset不支持降级操作。

##### Sorted Set（有序集合）

保留了集合不能有重复成员的特性，但不同得是，有序集合中的元素是可以排序的，但是它和列表的使用索引下标作为排序依据不同的是，它给每个元素设置一个分数，作为排序的依据。

应用：排行榜

数据结构：一种是ziplist，另一种是skiplist（跳跃表）与dict的结合；
ziplist作为集合和作为哈希对象是一样的，member和score顺序存放，按照score从小到大顺序排列。
skiplist（跳跃表）是对有序链表进行的扩展，解决了有序链表结构查找特定值困难的问题，查找特定值的时间复杂度为O(logn)，他是一种可以代替平衡树的数据结构，有如下特点：

- 由很多层结构组成（类似于树形结构），通过这些层来加快访问其他节点的速度，一般来说，层的数量越多，访问其他节点的速度就越快；每次创建一个新跳跃表节点的时候，程序都根据幂次定律（power law，越大的值[层数]出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小，这个大小就是层的“高度”。
- 每一层都是一个有序的链表
- 最底层(Level 1)的链表包含所有元素
- 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
- 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。

###### 为什么用跳表而不用红黑树？

- 在做**范围查找**的时候，skiplist要比平衡树操作简单，只需要在找到最小值之后，对原始链表进行若干步的遍历就可以实现；在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点；
- 平衡树的**插入**和**删除**操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。
- 从算法实现难度上来比较，skiplist比平衡树要简单得多。

##### BitMap
setbit KEY_NAME OFFSET VALUE;offset是偏移量,value只能是0,1
应用：记录登录次数（活跃度）

##### 为什么要使用查找性能低的整型数组和压缩列表？

- 内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。
- 数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。

#### 脚本与管道
如果是组织大量的、无依赖关系的命令，可以选择管道，当然也可以选择脚本。
如果命令之间有依赖关系，比如后续的命令需要处理先前命令的返回值，只能选择脚本。

#### 事务
##### 特性：
事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行（任务中存在命令执行失败，其余命令仍会被执行）。

##### 事务中的错误

- 事务在执行 [EXEC](http://redis.cn/commands/exec.html) 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用 `maxmemory` 设置了最大内存限制的话）；
- 命令可能在 [EXEC](http://redis.cn/commands/exec.html) 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类

对于发生在 [EXEC](http://redis.cn/commands/exec.html) 执行之前的错误，客户端以前的做法是检查命令入队所得的返回值：如果命令入队时返回 `QUEUED` ，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会停止并取消这个事务。从 Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 [EXEC](http://redis.cn/commands/exec.html) 命令时，拒绝执行并自动放弃这个事务。

至于那些在 [EXEC](http://redis.cn/commands/exec.html) 命令执行之后所产生的错误， 并没有对它们进行特别处理： 即使事务中有某个/某些命令在执行时产生了错误， **事务中的其他命令仍然会继续执行**。这样做法的优点：

- Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。
- 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。

#### phpredis:connect与pconnect

* connect：脚本结束之后连接就释放了。

* pconnect：脚本结束之后连接不释放，连接保持在php-fpm进程中。

  所以使用pconnect代替connect，可以减少频繁建立redis连接的消耗。

  [pconnect弊端](https://www.v2ex.com/t/95635)

#### 阻塞

##### 5个阻塞点

- 集合全量查询和聚合操作；
- bigkey 删除；【可异步处理，惰性删除（lazy free）】
- 清空数据库（例如 FLUSHDB 和 FLUSHALL 操作）；【可异步处理，放入队列中】
- AOF 日志同步写；【可异步处理，AOF 日志配置成 everysec】
- 从库加载 RDB 文件。

##### lazy free(4.0新增的功能，但是默认是关闭的，需要手动开启)

- lazyfree-lazy-expire：key在过期删除时尝试异步释放内存

- lazyfree-lazy-eviction：内存达到maxmemory并设置了淘汰策略时尝试异步释放内存

- lazyfree-lazy-server-del：执行RENAME/MOVE等命令或需要覆盖一个key时，删除旧key尝试异步释放内存

- replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存

  即使开启了lazy-free，如果直接使用DEL命令还是会同步删除key，只有使用UNLINK命令才会可能异步删除key。

#### redis出现延迟的检查维度

1、使用复杂度过高的命令（例如SORT/SUION/ZUNIONSTORE/KEYS），或一次查询全量数据（例如LRANGE key 0 N，但N很大）

分析：a) 查看slowlog是否存在这些命令 b) Redis进程CPU使用率是否飙升（聚合运算命令导致）

解决：a) 不使用复杂度过高的命令，或用其他方式代替实现（放在客户端做） b) 数据尽量分批查询（LRANGE key 0 N，建议N<=100，查询全量数据建议使用HSCAN/SSCAN/ZSCAN）

2、操作bigkey

分析：a) slowlog出现很多SET/DELETE变慢命令（bigkey分配内存和释放内存变慢） b) 使用redis-cli -h $host -p $port --bigkeys扫描出很多bigkey

解决：a) 优化业务，避免存储bigkey b) Redis 4.0+可开启lazy-free机制

3、大量key集中过期

分析：a) 业务使用EXPIREAT/PEXPIREAT命令 b) Redis info中的expired_keys指标短期突增

解决：a) 优化业务，过期增加随机时间，把时间打散，减轻删除过期key的压力 b) 运维层面，监控expired_keys指标，有短期突增及时报警排查

4、Redis内存达到maxmemory

分析：a) 实例内存达到maxmemory，且写入量大，淘汰key压力变大 b) Redis info中的evicted_keys指标短期突增

解决：a) 业务层面，根据情况调整淘汰策略（随机比LRU快） b) 运维层面，监控evicted_keys指标，有短期突增及时报警 c) 集群扩容，多个实例减轻淘汰key的压力

5、大量短连接请求

分析：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时

解决：使用长连接操作Redis

6、生成RDB和AOF重写fork耗时严重

分析：a) Redis变慢只发生在生成RDB和AOF重写期间 b) 实例占用内存越大，fork拷贝内存页表越久 c) Redis info中latest_fork_usec耗时变长

解决：a) 实例尽量小 b) Redis尽量部署在物理机上 c) 优化备份策略（例如低峰期备份） d) 合理配置repl-backlog和slave client-output-buffer-limit，避免主从全量同步 e) 视情况考虑关闭AOF f) 监控latest_fork_usec耗时是否变长

7、AOF使用awalys机制

分析：磁盘IO负载变高

解决：a) 使用everysec机制 b) 丢失数据不敏感的业务不开启AOF

8、使用Swap

分析：a) 所有请求全部开始变慢 b) slowlog大量慢日志 c) 查看Redis进程是否使用到了Swap

解决：a) 增加机器内存 b) 集群扩容 c) Swap使用时监控报警

9、进程绑定CPU不合理

分析：a) Redis进程只绑定一个CPU逻辑核 b) NUMA架构下，网络中断处理程序和Redis进程没有绑定在同一个Socket下

解决：a) Redis进程绑定多个CPU逻辑核 b) 网络中断处理程序和Redis进程绑定在同一个Socket下

10、开启透明大页机制

分析：生成RDB和AOF重写期间，主线程处理写请求耗时变长（拷贝内存副本耗时变长）

解决：关闭透明大页机制

11、网卡负载过高

分析：a) TCP/IP层延迟变大，丢包重传变多 b) 是否存在流量过大的实例占满带宽

解决：a) 机器网络资源监控，负载过高及时报警 b) 提前规划部署策略，访问量大的实例隔离部署

#### memory

**used_memory：**Redis使用的内存总量，它包含了实际缓存占用的内存（包含虚拟内存）和Redis自身运行所占用的内存(如元数据、lua)。它是由Redis使用内存分配器分配的内存，不包含内存碎片。

**used_memory_rss**：从操作系统角度看redis进程占用的内存量。包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。

**内存碎片率：**mem_fragmentation_ratio = used_memory_rss / used_memory

- mem_fragmentation_ratio < 1：表示Redis内存分配超出了物理内存，使用了过多的虚拟内存，由于虚拟内存的媒介是磁盘（操作系统正在进行内存交换，引起非常明显的响应延迟），比内存速度要慢很多；

- mem_fragmentation_ratio > 1 是合理的；


### 主从

#### 主从同步

##### 第一次同步

- 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。
- 在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件；在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求，为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作
- 第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了；

一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销；

##### 网络断连或阻塞

当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区；repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置master_repl_offset，从库则会记录自己已经读到的位置slave_repl_offset。主从库的连接恢复之后，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。

如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。可以调大缓冲区；

### 哨兵

哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知；哨兵直接通过pub/sub 机制进行通信；

#### 判定下线

哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为**主观下线**。如果检测的是从库，那么哨兵简单地把它标记为“主观下线”就行了。如果是主库，需要一定数量的哨兵实例（少数服从多数，通过哨兵配置文件中的 quorum 配置项设定），都判断主库已经**主观下线**了，主库才会被标记为**客观下线**；然后就可以选取新主库；

#### 哨兵选leader

每个哨兵会请求其他哨兵为自己投票，其他哨兵节点对收到的第一个请求进行投票确认，一轮投票下来后，首先达到多数选票的哨兵节点成为“哨兵Leader”；在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到**半数以上的赞成票**；第二，拿到的票数同时还需要**大于等于哨兵配置文件中的 quorum 值**；如果没有达到多数选票的哨兵节点，那么会重新选举，直到能够成功选出“哨兵Leader”；

#### 选主

**先按一定条件筛选：**除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了；

接下来分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号；只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束：

- **优先级最高的从库得分高**，用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级；
- **和旧主库同步程度最接近的从库得分高**，这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么这个新主库上就有最新的数据。主从库同步时有个命令传播的过程，主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度；从库的 slave_repl_offset 最接近 master_repl_offset，得分就最高；
- **ID 号小的从库得分高**



### 分布式锁

在某些场景中，多个进程必须以互斥的方式独占共享资源，这时用分布式锁是最直接有效的；

#### 分布式锁需满足四个条件

1. 互斥性。在任意时刻，只有一个客户端能持有锁。
2. 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
3. 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了，即不能误解锁。
4. 具有容错性。只要大多数Redis节点正常运行，客户端就能够获取和释放锁。

#### 常见分布式锁

| 分类               | 方案                              | 实现原理                                                     | 优点                                                         | 缺点                                                         |
| ------------------ | --------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 基于数据库         | 基于mysql 表唯一索引              | 1.表增加唯一索引 2.加锁：执行insert语句，若报错，则表明加锁失败 3.解锁：执行delete语句 | 完全利用DB现有能力，实现简单                                 | 1.锁无超时自动失效机制，有死锁风险 2.不支持锁重入，不支持阻塞等待 3.操作数据库开销大，性能不高 |
| 基于数据库         | 基于MongoDB findAndModify原子操作 | 1.加锁：执行findAndModify原子命令查找document，若不存在则新增 2.解锁：删除document | 实现也很容易，较基于MySQL唯一索引的方案，性能要好很多        | 1.大部分公司数据库用MySQL，可能缺乏相应的MongoDB运维、开发人员 2.锁无超时自动失效机制 |
| 基于分布式协调系统 | 基于ZooKeeper                     | 1.加锁：在/lock目录下创建临时有序节点，判断创建的节点序号是否最小。若是，则表示获取到锁；否，则则watch /lock目录下序号比自身小的前一个节点 2.解锁：删除节点 | 1.由zk保障系统高可用 2.Curator框架已原生支持系列分布式锁命令，使用简单 | 需单独维护一套zk集群，维保成本高                             |
| 基于缓存           | 基于redis命令                     | 1. 加锁：执行setnx，若成功再执行expire添加过期时间 2. 解锁：执行delete命令 | 实现简单，相比数据库和分布式系统的实现，该方案最轻，性能最好 | 1.setnx和expire分2步执行，非原子操作；若setnx执行成功，但expire执行失败，就可能出现死锁 2.delete命令存在误删除非当前线程持有的锁的可能 3.不支持阻塞等待、不可重入 |
| 基于缓存           | 基于redis Lua脚本能力             | 1. 加锁：执行SET lock_name random_value EX seconds NX 命令  2. 解锁：执行Lua脚本，释放锁时验证random_value  -- ARGV[1]为random_value,  KEYS[1]为lock_nameif redis.call("get", KEYS[1]) == ARGV[1] then    return redis.call("del",KEYS[1])else    return 0end | 同上；实现逻辑上也更严谨，除了单点问题，生产环境采用用这种方案，问题也不大。 | 不支持**锁重入**，不支持**阻塞等待**                         |

#### redisson

相比以上方案，redisson保持了**简单易用、支持锁重入、支持阻塞等待、Lua脚本原子**操作；

##### 加锁lua脚本

```lua
-- KEYS[1]	my_first_lock_name	锁名
-- ARGV[1]	60000	持有锁的有效时间：毫秒
-- ARGV[2]	58c62432-bb74-4d14-8a00-9908cc8b828f:1	唯一标识：获取锁时set的唯一值，实现上为redisson客户端ID(UUID)+线程ID
-- 若锁不存在：则新增锁，并设置锁重入计数为1、设置锁过期时间
if (redis.call('exists', KEYS[1]) == 0) then
    redis.call('hset', KEYS[1], ARGV[2], 1);
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;
 
-- 若锁存在，且唯一标识也匹配：则表明当前加锁请求为锁重入请求，故锁重入计数+1，并再次设置锁过期时间
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then
    redis.call('hincrby', KEYS[1], ARGV[2], 1);
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;
 
-- 若锁存在，但唯一标识不匹配：表明锁是被其他线程占用，当前线程无权解他人的锁，直接返回锁剩余过期时间
return redis.call('pttl', KEYS[1]);
```

##### 加锁流程

1、尝试获取锁，这一步是通过执行加锁Lua脚本来做；

2、若第一步未获取到锁，则去订阅解锁消息，当获取锁到剩余过期时间后，调用信号量方法阻塞住，直到被唤醒或等待超时 

3、一旦持有锁的线程释放了锁，就会广播解锁消息。于是，第二步中的解锁消息的监听器会释放信号量，获取锁被阻塞的那些线程就会被唤醒，并重新尝试获取锁

**自动延长锁有效期**：获取到锁之后，开启定时器，会每隔十秒钟异步执行一段lua脚本，在锁key还没有失效的情况下，会把锁的过期时间继续延长到30000毫秒，也就是说只要这台服务实例没有挂掉，并且没有主动释放锁；

**锁的可重入性**：当前客户端的别的线程来获取锁，当加锁的锁key存在的时候并且锁key对应的map结构中当前客户端的唯一key也存在时，会去调用hincrby命令，将唯一key的值自增一，并且会pexpire设置key的过期时间为30000毫秒，然后返回nil,可以想象这里也是加锁成功的，也会继续去执行定时调度任务，完成锁key过期时间的续约；

##### 解锁lua脚本

```lua
-- KEYS[1]	my_first_lock_name	锁名
-- KEYS[2]	redisson_lock__channel:{my_first_lock_name}	解锁消息PubSub频道
-- ARGV[1]	0	redisson定义0表示解锁消息
-- ARGV[2]	30000	设置锁的过期时间；默认值30秒
-- ARGV[3]	58c62432-bb74-4d14-8a00-9908cc8b828f:1	唯一标识；同加锁流程
-- 若锁不存在：则直接广播解锁消息，并返回1
if (redis.call('exists', KEYS[1]) == 0) then
    redis.call('publish', KEYS[2], ARGV[1]);
    return 1; 
end;
 
-- 若锁存在，但唯一标识不匹配：则表明锁被其他线程占用，当前线程不允许解锁其他线程持有的锁
if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then
    return nil;
end; 
 
-- 若锁存在，且唯一标识匹配：则先将锁重入计数减1
local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); 
if (counter > 0) then 
    -- 锁重入计数减1后还大于0：表明当前线程持有的锁还有重入，不能进行锁删除操作，但可以友好地帮忙设置下过期时期
    redis.call('pexpire', KEYS[1], ARGV[2]); 
    return 0; 
else 
    -- 锁重入计数已为0：间接表明锁已释放了。直接删除掉锁，并广播解锁消息，去唤醒那些争抢过锁但还处于阻塞中的线程
    redis.call('del', KEYS[1]); 
    redis.call('publish', KEYS[2], ARGV[1]); 
    return 1;
end;
 

```

#### 多线程竞争锁的流程

![img](https://img-blog.csdnimg.cn/20191231121113763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3czNzI0MjYwOTY=,size_16,color_FFFFFF,t_70)

1、线程A和线程B两个线程同时争抢锁。线程A很幸运，最先抢到了锁。线程B在获取锁失败后，并未放弃希望，而是主动订阅了解锁消息，然后再尝试获取锁，顺便看看没有抢到的这把锁还有多久就过期，线程B就按需阻塞等锁释放。

2、线程A拿着锁干完了活，自觉释放了持有的锁，于此同时广播了解锁消息，通知其他抢锁的线程再来枪；

3、解锁消息的监听者LockPubSub收到消息后，释放自己持有的信号量；线程B就瞬间从阻塞中被唤醒了，接着再抢锁，这次终于抢到锁了！后面再按部就班，干完活，解锁